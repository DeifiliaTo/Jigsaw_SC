cp: target '/hkfs/work/workspace/scratch/ke4365-summa/experiments/scaling/strong_scaling/2_1tflop/two/src' is not a directory
Restoring modules from user's pangu, for system: "hk"
/hkfs/work/workspace/scratch/ke4365-summa/.venv/bin/python
MASTER_ADDR=hkn0432
GpuFreq=control_disabled
Rank 0: world_size 2, slurm_localid 0
Rank 1: world_size 2, slurm_localid 1
Rank 1/2: Process group initialized with torch rank 1 and torch world size 2.
Rank 0/2: Process group initialized with torch rank 0 and torch world size 2.
Training parameters {'lr': 0.0001, 'lr_embedding': 2e-05, 'lr_recovery': 2e-05, 'loss': 'L2', 'lr_constant': False, 'train_batch': 1, 'valid_batch': 1, 'identity': False, 'grad_clip': 10, 'save_dir': '/hkfs/work/workspace/scratch/ke4365-summa/experiments/scaling/strong_scaling/hundred_million/one', 'preload': False, 'file_path': '/hkfs/work/workspace/scratch/ke4365-summa/experiments/scaling/strong_scaling/hundred_million/one', 'load_path': '/hkfs/work/workspace/scratch/ke4365-summa/experiments/scaling/strong_scaling/hunderd_million/one', 'area_weighted': True, 'print': True, 'tf32': True}
Model parameters {'hidden_dim': 896, 'spatial_hidden_dim_fraction': 0.125, 'features_hidden_dim_fraction': 1, 'mixing_blocks': 3, 'model_parallel': True, 'patch_size': 60, 'stride': 60, 'add': False, 'positional_encoding': False, 'patch_embed': 1, 'latent_rollout': 1, 'upt': False, 'concat': True, 'linear_residual': True, 'dropout': 0.001}
Training subset size 1250
Reading from /hkfs/work/workspace/scratch/ke4365-era5_data/era5_subset.zarr
[Errno 2] No such file or directory: '/hkfs/work/workspace/scratch/ke4365-summa/experiments/scaling/strong_scaling/hunderd_million/one/model_1.pt'
Rank 1 running on CPU core: 151 Allocated GPU(s):, 0,1
model has 240.470184 million parameters
Estimated forward TFLOPs and GB_COMM: 0.9904387966639998, 0.6397286653518677
[Errno 2] No such file or directory: '/hkfs/work/workspace/scratch/ke4365-summa/experiments/scaling/strong_scaling/hunderd_million/one/model_0.pt'
Initializing model from scratch
Rank 0 running on CPU core: 37 Allocated GPU(s):, 0,1
/hkfs/work/workspace/scratch/ke4365-summa/.venv/lib64/python3.11/site-packages/torch/autograd/function.py:575: UserWarning: TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (Triggered internally at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:3436.)
  return super().apply(*args, **kwargs)  # type: ignore[misc]
/hkfs/work/workspace/scratch/ke4365-summa/.venv/lib64/python3.11/site-packages/torch/autograd/function.py:575: UserWarning: TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (Triggered internally at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:3436.)
  return super().apply(*args, **kwargs)  # type: ignore[misc]
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 2995899 ON hkn0432 CANCELLED AT 2025-03-19T08:07:43 ***
slurmstepd: error: *** STEP 2995899.0 ON hkn0432 CANCELLED AT 2025-03-19T08:07:43 ***

============================= JOB FEEDBACK =============================

Job ID: 2995899
Cluster: hk
User/Group: ke4365/hk-project-epais
Account: hk-project-p0021348
State: CANCELLED (exit code 0)
Partition: accelerated
Nodes: 1
Cores per node: 152
Nodelist: hkn0432
CPU Utilized: 13:15:44
CPU Efficiency: 6.02% of 9-04:24:00 core-walltime
Job Wall-clock time: 01:27:00
Starttime: Wed Mar 19 06:40:43 2025
Endtime: Wed Mar 19 08:07:43 2025
Memory Utilized: 51.15 GB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
Energy Consumed: 3560284 Joule / 988.967777777778 Watthours
Average node power draw: 682.046743295019 Watt
